# Technical developments

## An innovative practice for the capture of historical data: the STAR model

The treatment of historical information as a collection of assertions rather than plain facts is the methodological basis of RELEVEN. We therefore need to address the question of how we can robustly express conflicting information in our histor-ical sources and our present-day reconstructions and even how we can use digital methods to express the multi-perspectivity that is so sought after in today’s his-torical methodology. In so doing, we aim to provide a clear counter-example to the common assumption that digital history projects are positivistic by their very nature. The opportunity to do this is provided by our focus on the eleventh-century Christian world, which involves very many perspectives and very contested events, of which only one or two narratives are generally known. At the heart of our digital work is the STAR model, which stands for STructured Assertion Record. We use the STAR model to approach the problem that, on the one hand, Linked Open Data (LOD) is a very popular model for many sorts of data col-lections, including those within the cultural heritage domain. On the other hand, as mentioned above, LOD was designed basically without controversy in mind. One of the consequences of its design is that the collection of facts, or assertions, repre-sented in an LOD store tends to get dissociated very quickly from the context that is very often associated with important meaning or cultural implications for the data that was collected.5 The other common approach, known as the ‘factoid model,’ used primarily in prosopographical databases,6 has the strength that its data statements are always connected to the primary source from which it was taken, but the weak-ness is that if a statement is not made in a primary source, it cannot be represented in the database at all.

The schematic of a typical LOD statement is given in Figure 1a: it consists of an entity that is the subject of the statement, a relationship that denotes a property of that entity—one might think of this as the verb—and an object, which is the value (or content) of that property. The same statement is represented in Figure 1b according to the STAR model. The statement is now rather more complex: the rela-tionship (or property) that was previously only a connection between two entities is now itself an entity. This is known as ‘reification.’ All three entities—the subject, predicate, and object—are then connected to a core ‘assertion’ object, which also provides a connection to an entity representing the authority for the statement (that is, who made the claim) and one representing the source (that is, on what basis the claim was made).One of the first crucial tasks was to find out how our approach could fit with existing models, if at all. Indeed, the problem of conflicting assertions has received an increasing amount of attention in the last several years, and a relevant revision was published in 2019 to the CIDOC Conceptual Reference Model (CIDOC-CRM), which is increasingly becoming the fundamental standard for the computational modelling and representation  of  cultural  heritage  data. We have based the specifics of our model on CIDOC-CRM version 7.1.2; the specific entities and properties we have adopted to form the assertions are shown in Figure 2. The use of our STAR model to represent the data we collect underpins each of the case stud-ies presented below.

## Towards declarative linked data backends: generating the RELEVEN graph API from RDF path expressions

Linked data and knowledge graph technologies are powerful tools for integrating, connecting, and reasoning over complex information from diverse sources. They excel at revealing relationships between entities, supporting semantic search, and powering AI systems with structured context. However, for non-specialist users, the technical representations of triples, ontologies, and graph structures can be difficult to understand and interact with. To make these benefits accessible, simpler, more intuitive data representations—such as tables, visual maps, or natural language interfaces—are often needed to bridge the gap between advanced semantic technologies and everyday users.

We address this problem with [`rdfproxy`](https://github.com/acdh-oeaw/rdfproxy), a Python library for mapping SPARQL query results to Pydantic models, which allows building REST APIs on top of SPARQL endpoints.

Toolchain demo: <https://erc-releven.github.io/releven-backend>
